{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup langsmith "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import os\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY') # Update to your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "# connection of Astra DB\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_ID = os.getenv(\"ASTRA_DB_ID\")\n",
    "\n",
    "cassio.init(\n",
    "    token = ASTRA_DB_APPLICATION_TOKEN,\n",
    "    database_id = ASTRA_DB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TAMU\\SEM 4\\CNM\\BrokenBasket\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Cassandra\n",
    "astra_vector_store = Cassandra(embedding=embeddings,\n",
    "                               table_name = \"CNM_test_table\",\n",
    "                               session=None,\n",
    "                               keyspace=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='53874fa27eca451281e0084ab85c34f3', metadata={'description': 'These are THE BEST soft chocolate chip cookies! No chilling required. Just ultra thick, soft, classic chocolate chip cookies!', 'language': 'en-US', 'source': 'https://pinchofyum.com/the-best-soft-chocolate-chip-cookies', 'title': 'The Best Soft Chocolate Chip Cookies Recipe - Pinch of Yum'}, page_content='Me \\nLindsay was kind enough to post this perfect recipe. I think you can figure this one out yourself‚Ä¶ Smh\\n\\n\\n\\n04/21/16 @ 8:56 pm\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nhoi \\nYah, toats agree vith Zou!\\n \\n\\n04/30/16 @ 10:00 am\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKevin \\nMaybe you shouldn‚Äôt be so weirdly hateful in the comments section of a yummy chocolate chip cookies recipe? This is supposed to be fun, right?\\n\\n\\n\\n12/24/16 @ 9:30 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\njacquelyn karney \\nIf you are making chocolate chip cookies, who cares about the nutritional information?\\n \\n\\n06/15/19 @ 11:36 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nRenae Graham \\nDo you use anything on the pan? Like a nonstick spray? Or just right onto the pan\\n \\n\\n01/11/21 @ 6:35 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKrista @ Pinch of Yum \\nWe don‚Äôt use anything on the pan!\\n \\n\\n01/13/21 @ 5:11 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nIsa \\nMy favourite go-to cookie recipe!!! I‚Äôve done it close to 10 times now.\\n\\n\\n\\n02/17/24 @ 2:22 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nOlivia \\nThere is no nutrition.  Seriously you must know tgat\\n \\n\\n07/09/16 @ 7:22 am\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nAlex \\nLoved the infomation that comes with this great recipe! Cookies are amazing \\uf8ffüôÇ\\n\\n\\n\\n11/29/17 @ 9:43 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKay \\nMade these last night and they turned out good, a little salty perhaps unsalted butter should be used? But they were still soft the next day which is amazing for the holidays!\\n\\n\\n\\n11/12/19 @ 7:52 am'),\n",
       " Document(id='e8a76689f5c84bd68afa035ef900ad26', metadata={'description': 'These are THE BEST soft chocolate chip cookies! No chilling required. Just ultra thick, soft, classic chocolate chip cookies!', 'language': 'en-US', 'source': 'https://pinchofyum.com/the-best-soft-chocolate-chip-cookies', 'title': 'The Best Soft Chocolate Chip Cookies Recipe - Pinch of Yum'}, page_content='Me \\nLindsay was kind enough to post this perfect recipe. I think you can figure this one out yourself‚Ä¶ Smh\\n\\n\\n\\n04/21/16 @ 8:56 pm\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nhoi \\nYah, toats agree vith Zou!\\n \\n\\n04/30/16 @ 10:00 am\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKevin \\nMaybe you shouldn‚Äôt be so weirdly hateful in the comments section of a yummy chocolate chip cookies recipe? This is supposed to be fun, right?\\n\\n\\n\\n12/24/16 @ 9:30 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\njacquelyn karney \\nIf you are making chocolate chip cookies, who cares about the nutritional information?\\n \\n\\n06/15/19 @ 11:36 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nRenae Graham \\nDo you use anything on the pan? Like a nonstick spray? Or just right onto the pan\\n \\n\\n01/11/21 @ 6:35 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKrista @ Pinch of Yum \\nWe don‚Äôt use anything on the pan!\\n \\n\\n01/13/21 @ 5:11 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nIsa \\nMy favourite go-to cookie recipe!!! I‚Äôve done it close to 10 times now.\\n\\n\\n\\n02/17/24 @ 2:22 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nOlivia \\nThere is no nutrition.  Seriously you must know tgat\\n \\n\\n07/09/16 @ 7:22 am\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nAlex \\nLoved the infomation that comes with this great recipe! Cookies are amazing \\uf8ffüôÇ\\n\\n\\n\\n11/29/17 @ 9:43 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKay \\nMade these last night and they turned out good, a little salty perhaps unsalted butter should be used? But they were still soft the next day which is amazing for the holidays!\\n\\n\\n\\n11/12/19 @ 7:52 am'),\n",
       " Document(id='57be00175bc34853b85ae3ac9a1b5e30', metadata={'description': 'These are THE BEST soft chocolate chip cookies! No chilling required. Just ultra thick, soft, classic chocolate chip cookies!', 'language': 'en-US', 'source': 'https://pinchofyum.com/the-best-soft-chocolate-chip-cookies', 'title': 'The Best Soft Chocolate Chip Cookies Recipe - Pinch of Yum'}, page_content='Me \\nLindsay was kind enough to post this perfect recipe. I think you can figure this one out yourself‚Ä¶ Smh\\n\\n\\n\\n04/21/16 @ 8:56 pm\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nhoi \\nYah, toats agree vith Zou!\\n \\n\\n04/30/16 @ 10:00 am\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKevin \\nMaybe you shouldn‚Äôt be so weirdly hateful in the comments section of a yummy chocolate chip cookies recipe? This is supposed to be fun, right?\\n\\n\\n\\n12/24/16 @ 9:30 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\njacquelyn karney \\nIf you are making chocolate chip cookies, who cares about the nutritional information?\\n \\n\\n06/15/19 @ 11:36 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nRenae Graham \\nDo you use anything on the pan? Like a nonstick spray? Or just right onto the pan\\n \\n\\n01/11/21 @ 6:35 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKrista @ Pinch of Yum \\nWe don‚Äôt use anything on the pan!\\n \\n\\n01/13/21 @ 5:11 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nIsa \\nMy favourite go-to cookie recipe!!! I‚Äôve done it close to 10 times now.\\n\\n\\n\\n02/17/24 @ 2:22 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nOlivia \\nThere is no nutrition.  Seriously you must know tgat\\n \\n\\n07/09/16 @ 7:22 am\\n\\n\\nReply \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nAlex \\nLoved the infomation that comes with this great recipe! Cookies are amazing \\uf8ffüôÇ\\n\\n\\n\\n11/29/17 @ 9:43 pm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nKay \\nMade these last night and they turned out good, a little salty perhaps unsalted butter should be used? But they were still soft the next day which is amazing for the holidays!\\n\\n\\n\\n11/12/19 @ 7:52 am'),\n",
       " Document(id='4e713e56a6f84efd8285a9189b2c73bd', metadata={'description': 'These are THE BEST soft chocolate chip cookies! No chilling required. Just ultra thick, soft, classic chocolate chip cookies!', 'language': 'en-US', 'source': 'https://pinchofyum.com/the-best-soft-chocolate-chip-cookies', 'title': 'The Best Soft Chocolate Chip Cookies Recipe - Pinch of Yum'}, page_content='5 Stars\\t\\t\\t        \\t\\t\\t\\t4 Stars\\t\\t\\t        \\t\\t\\t\\t3 Stars\\t\\t\\t        \\t\\t\\t\\t2 Stars\\t\\t\\t        \\t\\t\\t\\t1 Star\\t\\t\\t  \\n4.5 from 1861 reviews\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAuthor: Pinch of Yum \\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tTotal Time: 20 minutes \\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tYield: 12 cookies \\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\tPrint\\n\\n\\n\\n\\n\\t\\tPin\\n\\n\\n\\n\\nDescription\\n\\nThese are THE BEST soft chocolate chip cookies! No chilling required. Just ultra thick, soft, classic chocolate chip cookies!\\n\\n\\n\\n\\n\\n\\nIngredients\\n\\n\\n\\nUnits\\nUSM \\n\\n\\n\\n\\n8 tablespoons of salted butter\\n1/2 cup white sugar (I like to use raw cane sugar with a coarser texture)\\n1/4 cup packed light brown sugar\\n1 teaspoon vanilla\\n1 egg\\n1 1/2 cups all purpose flour (6.75 ounces)\\n1/2 teaspoon baking soda\\n1/4 teaspoon salt (but I always add a little extra)\\n3/4 cup chocolate chips (I use a combination of chocolate chips and chocolate chunks)\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nCook Mode\\n\\n\\t\\t\\t\\tPrevent your screen from going dark\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\nInstructions\\n\\nVideo\\n\\nOn\\nOff')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = astra_vector_store.as_retriever()\n",
    "retriever.invoke(\"Give me a cookie recipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TAMU\\SEM 4\\CNM\\BrokenBasket\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3549: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# langgraph application\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "  \"\"\"Route a user query to the most relevant datasource\"\"\"\n",
    "  datasource: Literal[\"vectorstore\",\"chat\"] = Field(\n",
    "      ...,\n",
    "      description=\"Given a user question choose to route it to chat or a vectorstore\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "groq_api_key = os.getenv('groq_api_key')\n",
    "# print(groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name='Llama-3.3-70b-Versatile')\n",
    "structured_llm_router=llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='chat'\n",
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or chat.\n",
    "The vectorstore contains documents related to baking recipes.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use chat.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"message\": \"what is stardew Valley\"}\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"message\": \"How to make a sweet dessert\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatGroq(groq_api_key=groq_api_key,model_name='Llama-3.3-70b-Versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph\n",
    "\n",
    "from typing import List,Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "def trim(state):\n",
    "    response = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        # Keep the last <= n_count tokens of the messages.\n",
    "        strategy=\"last\",\n",
    "        token_counter=len,\n",
    "        # When token_counter=len, each message\n",
    "        # will be counted as a single token.\n",
    "        # Remember to adjust for your use case\n",
    "        max_tokens=4,\n",
    "        # Most chat models expect that chat history starts with either:\n",
    "        # (1) a HumanMessage or\n",
    "        # (2) a SystemMessage followed by a HumanMessage\n",
    "        start_on=\"human\",\n",
    "        # Most chat models expect that chat history ends with either:\n",
    "        # (1) a HumanMessage or\n",
    "        # (2) a ToolMessage\n",
    "        end_on=(\"human\", \"tool\"),\n",
    "        # Usually, we want to keep the SystemMessage\n",
    "        # if it's present in the original history.\n",
    "        # The SystemMessage has special instructions for the model.\n",
    "        include_system=True,\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot(state):\n",
    "    response = chat_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"chat\", chat_bot)\n",
    "workflow.add_node(\"trim\", trim)\n",
    "\n",
    "workflow.add_edge(START, \"trim\")\n",
    "workflow.add_edge(\"trim\", \"chat\")\n",
    "workflow.add_edge(\"chat\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't know your name. I'm a large language model, I don't have the ability to know personal information about you, including your name. I can only respond based on the input you provide. If you'd like to share your name, I'd be happy to chat with you and use it in our conversation.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "input_message = [HumanMessage(content=\"What is my name?\")]\n",
    "output = app.invoke({\"messages\":input_message},config=config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, John. It's great that you've shared your name with me. I'll do my best to address you by name in our conversation. Is there something I can help you with or would you like to chat about a particular topic, John?\n"
     ]
    }
   ],
   "source": [
    "input_message = [HumanMessage(content=\"my name is John\")]\n",
    "output = app.invoke({\"messages\":input_message},config=config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = [HumanMessage(content=\"is Aarush dumb?\")]\n",
    "output = app.invoke({\"messages\":input_message},config=config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
